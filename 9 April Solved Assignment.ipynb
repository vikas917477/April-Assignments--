{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372a908a",
   "metadata": {},
   "source": [
    "# Na√Øve bayes-1\n",
    "Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507da00",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2efdfa3",
   "metadata": {},
   "source": [
    "Bayes' theorem is a mathematical formula that describes the relationship between conditional probabilities. It is named after the English statistician Thomas Bayes, who first formulated the theorem in the 18th century. The theorem states that the probability of a hypothesis H (such as the occurrence of an event) given some observed evidence E is proportional to the probability of the evidence given the hypothesis times the prior probability of the hypothesis, divided by the probability of the evidence overall:\n",
    "\n",
    "P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "where:\n",
    "\n",
    "P(H|E) is the probability of the hypothesis given the evidence\n",
    "P(E|H) is the probability of the evidence given the hypothesis\n",
    "P(H) is the prior probability of the hypothesis (before considering the evidence)\n",
    "P(E) is the probability of the evidence (before considering the hypothesis)\n",
    "Bayes' theorem is widely used in statistics, machine learning, and other fields to update beliefs or predictions based on new evidence. It provides a way to incorporate prior knowledge or assumptions into a model and adjust them based on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21980b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "82c67f24",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081644b9",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A (before considering event B)\n",
    "P(B) is the probability of event B (before considering event A)\n",
    "Bayes' theorem is often used to update the probability of a hypothesis (A) based on observed evidence (B). The theorem states that the posterior probability of A given B is proportional to the likelihood of B given A times the prior probability of A, divided by the marginal likelihood of B. The marginal likelihood of B is the probability of observing B under all possible values of A, and it acts as a normalization factor to ensure that the probabilities sum to one. Bayes' theorem is a fundamental tool in Bayesian statistics and machine learning, where it is used to make predictions and infer parameters of models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "753f30a8",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514562b",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice in many fields, including statistics, machine learning, artificial intelligence, and data science. Here are a few examples of how it is used:\n",
    "\n",
    "1. Medical diagnosis: Bayes' theorem can be used to calculate the probability of a patient having a certain disease based on their symptoms and medical history. The prior probability would be the prevalence of the disease in the general population, and the likelihood would be the probability of observing the patient's symptoms given that they have the disease.\n",
    "\n",
    "2. Spam filtering: Bayes' theorem can be used to classify emails as spam or not spam. The prior probability would be the proportion of emails that are spam in the total number of emails, and the likelihood would be the probability of observing certain words or phrases in the email given that it is spam.\n",
    "\n",
    "3. Stock market predictions: Bayes' theorem can be used to make predictions about future stock prices. The prior probability would be the probability of a certain event happening in the stock market (such as a recession), and the likelihood would be the probability of observing certain market indicators (such as the price-to-earnings ratio) given that the event has occurred.\n",
    "\n",
    "4. Image recognition: Bayes' theorem can be used to classify images into different categories. The prior probability would be the proportion of images in each category, and the likelihood would be the probability of observing certain features (such as edges or colors) in the image given that it belongs to a particular category.\n",
    "\n",
    "These are just a few examples of how Bayes' theorem can be applied in practice. It is a powerful tool for making predictions and updating beliefs based on new evidence, and it is widely used in many fields to analyze data and make decisions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ac819c4",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d52c6",
   "metadata": {},
   "source": [
    "Bayes' theorem is a mathematical formula that relates conditional probabilities. It provides a way to update the probability of a hypothesis (such as the occurrence of an event) based on new evidence or observations.\n",
    "\n",
    "In particular, Bayes' theorem relates the conditional probability of a hypothesis given some observed evidence (known as the posterior probability) to the conditional probability of the evidence given the hypothesis (known as the likelihood), the prior probability of the hypothesis (before considering the evidence), and the marginal likelihood of the evidence (also known as the evidence or the normalizing constant).\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability is that the likelihood term in Bayes' theorem is a conditional probability. It represents the probability of observing the evidence given a certain hypothesis or model. Similarly, the posterior probability in Bayes' theorem is also a conditional probability. It represents the probability of the hypothesis given the evidence or observations.\n",
    "\n",
    "Thus, Bayes' theorem is a powerful tool for updating beliefs or making predictions based on conditional probabilities. It provides a way to incorporate prior knowledge or assumptions into a model and adjust them based on new data or evidence."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c03ae458",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f329c",
   "metadata": {},
   "source": [
    "There are several types of Naive Bayes classifiers, including Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions that can be made about it. Here are some general guidelines for choosing a Naive Bayes classifier:\n",
    "\n",
    "1. Gaussian Naive Bayes: This classifier assumes that the features are continuous and follow a normal (Gaussian) distribution. It is appropriate for problems where the data can be modeled as a continuous variable, such as predicting the price of a house based on its size and location.\n",
    "\n",
    "2. Multinomial Naive Bayes: This classifier assumes that the features are discrete and follow a multinomial distribution. It is appropriate for problems where the data consists of counts or frequencies, such as classifying documents based on their word frequencies.\n",
    "\n",
    "3. Bernoulli Naive Bayes: This classifier assumes that the features are binary (either present or absent) and follow a Bernoulli distribution. It is appropriate for problems where the data consists of binary features, such as classifying emails as spam or not spam based on the presence of certain words.\n",
    "\n",
    "In general, it is a good idea to try different types of Naive Bayes classifiers and compare their performance on the specific problem at hand. This can be done by using cross-validation or other techniques to evaluate the accuracy of the classifiers on a test set. It is also important to preprocess the data appropriately and choose the right features to obtain the best performance from any Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e17671df",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788781fb",
   "metadata": {},
   "source": [
    "To classify the new instance with features X1=3 and X2=4 using Naive Bayes, we need to calculate the posterior probabilities for each class and choose the class with the highest probability.\n",
    "\n",
    "Let's start by calculating the prior probabilities for each class, assuming equal prior probabilities:\n",
    "\n",
    "P(A) = 0.5\n",
    "P(B) = 0.5\n",
    "\n",
    "Next, we need to calculate the likelihood probabilities for each feature value and class. We will use the Naive Bayes assumption that the features are conditionally independent given the class.\n",
    "\n",
    "For class A:\n",
    "\n",
    "P(X1=3|A) = 4/13\n",
    "P(X2=4|A) = 3/13\n",
    "\n",
    "For class B:\n",
    "\n",
    "P(X1=3|B) = 1/7\n",
    "P(X2=4|B) = 1/7\n",
    "\n",
    "We can now use Bayes' theorem to calculate the posterior probabilities for each class:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) / P(X1=3,X2=4)\n",
    "P(B|X1=3,X2=4) = P(X1=3|B) * P(X2=4|B) * P(B) / P(X1=3,X2=4)\n",
    "\n",
    "Since the denominator P(X1=3,X2=4) is the same for both classes, we can ignore it for the purpose of comparison:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3|A) * P(X2=4|A) * P(A)\n",
    "P(B|X1=3,X2=4) = P(X1=3|B) * P(X2=4|B) * P(B)\n",
    "\n",
    "Plugging in the values we calculated earlier, we get:\n",
    "\n",
    "P(A|X1=3,X2=4) = (4/13) * (3/13) * 0.5 = 0.0407\n",
    "P(B|X1=3,X2=4) = (1/7) * (1/7) * 0.5 = 0.0018\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance belongs to class A, since it has the higher posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154dc73",
   "metadata": {},
   "source": [
    "# ThankYou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf46e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
